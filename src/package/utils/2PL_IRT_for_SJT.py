import numpy as np
from pathlib import Path
import json
import pandas as pd
from girth import twopl_mml
from package.utils import TRAIT_ORDER, get_project_root

# ================= 1. æ•°æ®åŠ è½½éƒ¨åˆ† =================
def load_sjt_scoring_table() -> dict:
    project_root = get_project_root()
    sjt_path = project_root / "src" / "package" / "utils" / "sjt_outputs" / "SJT_all_traits.json"
    if not sjt_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° SJT_all_traits.json: {sjt_path}")
    sjt_data = json.loads(sjt_path.read_text(encoding="utf-8"))
    name_to_code = {name: code for code, name in TRAIT_ORDER}
    scoring_table: dict = {}
    traits = sjt_data.get("traits", {})
    for trait_name, trait_block in traits.items():
        items = trait_block.get("items", [])
        trait_code = name_to_code.get(trait_name)
        if not trait_code:
            continue
        for item in items:
            item_id = item.get("item_id")
            if item_id is None:
                continue
            qid = f"Q{trait_code}_{item_id}"
            option_scores = {}
            options = item.get("options", {})
            for opt_key, opt_info in options.items():
                level = (opt_info.get("trait_level") or "").lower()
                option_scores[opt_key] = 1 if level == "high" else 0
            scoring_table[qid] = option_scores
    return scoring_table

def sjt_responses_to_matrix() -> pd.DataFrame:
    project_root = get_project_root()
    resp_path = project_root / "src" / "package" / "evaluators" / "sjt_responses.json"
    if not resp_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° sjt_responses.json: {resp_path}")
    responses = json.loads(resp_path.read_text(encoding="utf-8"))
    scoring_table = load_sjt_scoring_table()
    code_order = {code: idx for idx, (code, _) in enumerate(TRAIT_ORDER)}

    def _qid_sort_key(qid: str):
        try:
            trait_code = qid[1]
            item_part = qid.split("_", 1)[1]
            item_id = int(item_part)
        except Exception:
            trait_code = qid[1] if len(qid) > 1 else ""
            item_id = 0
        return (code_order.get(trait_code, 999), item_id, qid)

    all_qids = sorted(scoring_table.keys(), key=_qid_sort_key)
    rows = []
    for subj in responses:
        if subj.get("test_type") != "SJT":
            continue
        raw_sid = subj.get("è¢«è¯•ID")
        try:
            sid = str(int(float(raw_sid)))
        except Exception:
            sid = str(raw_sid)
        ans_list = subj.get("response") or []
        row_scores = {qid: None for qid in all_qids}
        for ans in ans_list:
            qid = ans.get("é¢˜ç›®ID")
            choice = ans.get("è¢«è¯•é€‰æ‹©")
            if not qid or not choice:
                continue
            if qid in scoring_table:
                score = scoring_table[qid].get(choice)
                if score is None:
                    score = 0
                row_scores[qid] = score
        rows.append(row_scores)

    df = pd.DataFrame(rows, columns=all_qids)
    df = df.astype(float)
    # å¤„ç†ç¼ºå¤±å€¼ï¼šå°†æ‰€æœ‰ NaN å¡«å……ä¸º 0ï¼ˆæœªå›ç­”çš„é¢˜ç›®è®¡ä¸º0åˆ†ï¼‰
    df = df.fillna(0)
    return df


def run_irt_analysis(raw_data):
    if isinstance(raw_data, pd.DataFrame):
        data_array = raw_data.values
        item_ids = raw_data.columns.tolist()
    else:
        data_array = np.array(raw_data)
        item_ids = [f"Item_{i}" for i in range(data_array.shape[1])]
    irt_data = data_array.T.astype(int)
    if irt_data.ndim != 2:
        raise ValueError(f"æ•°æ®ç»´åº¦é”™è¯¯ï¼æœŸæœ› 2ç»´çŸ©é˜µï¼Œå®é™…ä¸º {irt_data.ndim}ç»´ã€‚è¯·æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©ºæˆ–æ ¼å¼ä¸å¯¹ã€‚")
    print(f"âœ… æ•°æ®æ£€æŸ¥é€šè¿‡")
    print(f"   - é¢˜ç›®æ•°é‡ (Rows): {irt_data.shape[0]}")
    print(f"   - è¢«è¯•æ•°é‡ (Cols): {irt_data.shape[1]}")
    print("ğŸš€ æ­£åœ¨è¿è¡Œ 2PL IRT æ¨¡å‹ (å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
    try:
        results = twopl_mml(irt_data)
    except Exception as e:
        print("\nâŒ IRT æ¨¡å‹è®¡ç®—å¤±è´¥ï¼")
        print("å¸¸è§åŸå› ï¼š")
        print("1. æŸé“é¢˜æ‰€æœ‰äººå…¨å¯¹(å…¨1)æˆ–å…¨é”™(å…¨0) -> å¯¼è‡´æ–¹å·®ä¸º0")
        print("2. æ•°æ®åŒ…å«ç©ºå€¼(NaN)")
        raise e
    discrimination = results['Discrimination']  # a å‚æ•°
    difficulty = results['Difficulty']  # b å‚æ•°
    df_result = pd.DataFrame({
        'Item_ID': item_ids,
        'Discrimination_a': discrimination,
        'Difficulty_b': difficulty
    })
    return df_result


def load_sjt_items() -> dict:
    project_root = get_project_root()
    sjt_path = project_root / "src" / "package" / "utils" / "sjt_outputs" / "SJT_all_traits.json"
    if not sjt_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° SJT_all_traits.json: {sjt_path}")
    
    sjt_data = json.loads(sjt_path.read_text(encoding="utf-8"))
    name_to_code = {name: code for code, name in TRAIT_ORDER}
    items_dict = {}
    
    for trait_name, trait_block in sjt_data.get("traits", {}).items():
        trait_code = name_to_code.get(trait_name)
        if not trait_code:
            continue
        for item in trait_block.get("items", []):
            item_id = item.get("item_id")
            if item_id is None:
                continue
            qid = f"Q{trait_code}_{item_id}"
            items_dict[qid] = {**item, "trait_name": trait_name}
    return items_dict


def _load_irt_template() -> str:
    project_root = get_project_root()
    template_path = project_root / "src" / "package" / "utils" / "sjt_outputs" / "IRT_prompt.txt"
    if not template_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°IRT_prompt.txtæ¨¡æ¿æ–‡ä»¶: {template_path}")
    return template_path.read_text(encoding="utf-8")


def _format_item_content(item_id: str, item: dict) -> str:
    trait_name = item.get("trait_name", "æœªçŸ¥ç‰¹è´¨")
    situation = item.get("situation", "")
    question = item.get("question", "")
    options = item.get("options", {})
    lines = [
        f"Item_ID: {item_id}",
        f"Trait: {trait_name}",
        "åŸé¢˜ç›®:",
        f"  - æƒ…å¢ƒæè¿°: {situation}",
        f"  - æé—®: {question}",
        "  - é€‰é¡¹:"
    ]
    for opt_key in sorted(options.keys()):
        opt_info = options[opt_key]
        content = opt_info.get("content", "")
        trait_level = opt_info.get("trait_level", "")
        lines.append(f"    {opt_key}. {content} (ç‰¹è´¨æ°´å¹³: {trait_level})")
    return "\n".join(lines)


def _generate_diagnosis(discrimination_a: float, difficulty_b: float) -> str:
    diagnosis_parts = []
    if discrimination_a < 0.5:
        diagnosis_parts.append(
            f"ã€ä¸¥é‡é—®é¢˜ï¼šåŒºåˆ†åº¦æä½ (a={discrimination_a:.3f})ã€‘è¯¥é¢˜ç›®æ— æ³•æœ‰æ•ˆåŒºåˆ†è¢«è¯•æ°´å¹³ï¼Œå¯èƒ½å±äºå™ªéŸ³æ•°æ®ã€‚"
            f"é«˜ç‰¹è´¨å’Œä½ç‰¹è´¨çš„è¢«è¯•åœ¨é€‰ä»€ä¹ˆé€‰é¡¹ä¸Šæ²¡æœ‰æ˜æ˜¾å·®å¼‚ã€‚å»ºè®®å½»åº•é‡å†™æƒ…å¢ƒï¼Œç¡®ä¿é«˜åˆ†é€‰é¡¹å’Œä½åˆ†é€‰é¡¹åœ¨è¡Œä¸ºé€»è¾‘ä¸Šæœ‰æœ¬è´¨åŒºåˆ«ï¼Œé€‰é¡¹ç•Œé™è¿‡äºæ¨¡ç³Šã€‚"
        )
    elif discrimination_a < 0.8:
        diagnosis_parts.append(
            f"ã€é—®é¢˜ï¼šåŒºåˆ†åº¦ä¸€èˆ¬ (a={discrimination_a:.3f})ã€‘é¢˜ç›®åŒºåˆ†èƒ½åŠ›æœ‰å¾…æå‡ã€‚"
            f"å»ºè®®å¾®è°ƒé€‰é¡¹æªè¾ï¼Œå¢å¼ºé«˜åˆ†é€‰é¡¹çš„ç‰¹è´¨æŒ‡å‘æ€§ï¼Œä½¿é€‰é¡¹ä¹‹é—´çš„å·®å¼‚æ›´åŠ æ˜æ˜¾ã€‚"
        )
    if difficulty_b < -3.0:
        diagnosis_parts.append(
            f"ã€ä¸¥é‡é—®é¢˜ï¼šé¢˜ç›®å¤ªå®¹æ˜“ (b={difficulty_b:.3f})ã€‘å‡ ä¹æ‰€æœ‰äººéƒ½é€‰äº†é«˜åˆ†é¡¹ï¼ˆå¾—1åˆ†ï¼‰ï¼Œè¯´æ˜ä½åˆ†å¹²æ‰°é¡¹æ¯«æ— å¸å¼•åŠ›ã€‚"
            f"å»ºè®®å¢åŠ å¹²æ‰°é¡¹(ä½åˆ†é€‰é¡¹)çš„åˆç†æ€§å’Œå¸å¼•åŠ›ï¼Œä¸è¦è®©ä½åˆ†é¡¹çœ‹èµ·æ¥å¤ªæ„šè ¢æˆ–ä¸åˆç†ã€‚"
        )
    elif difficulty_b > 3.0:
        diagnosis_parts.append(
            f"ã€ä¸¥é‡é—®é¢˜ï¼šé¢˜ç›®å¤ªéš¾ (b={difficulty_b:.3f})ã€‘å‡ ä¹æ²¡äººé€‰é«˜åˆ†é¡¹ï¼ˆå¾—0åˆ†ï¼‰ï¼Œè¯´æ˜é«˜åˆ†é€‰é¡¹å¤ªæç«¯æˆ–å¤ªæ€ªå¼‚ã€‚"
            f"å»ºè®®é™ä½æ­£ç¡®é€‰é¡¹(é«˜åˆ†é€‰é¡¹)çš„é—¨æ§›ï¼Œä½¿å…¶ååº”æ›´ç¬¦åˆå¸¸ç†ï¼Œä¸è¦è¿‡äºæç«¯æˆ–ç†æƒ³åŒ–ã€‚"
        )
    return "\n".join(diagnosis_parts) if diagnosis_parts else "ã€å‚æ•°è¡¨ç°ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–ã€‘"


def generate_item_revision_prompt(bad_items: pd.DataFrame) -> str:
    if bad_items.empty:
        return ""
    template = _load_irt_template()
    items_dict = load_sjt_items()
    all_items_text = []
    for _, row in bad_items.iterrows():
        item_id = row['Item_ID']
        if item_id not in items_dict:
            continue
        item_text = _format_item_content(item_id, items_dict[item_id])
        diagnosis_text = _generate_diagnosis(row['Discrimination_a'], row['Difficulty_b'])
        all_items_text.append(f"{item_text}\nã€æ•°æ®è¯Šæ–­æ„è§ã€‘\n{diagnosis_text}")
    if not all_items_text:
        return ""
    return template.replace("ã€å¾…ä¼˜åŒ–é¢˜ç›®åŠæ•°æ®è¯Šæ–­æ„è§ã€‘", "\n\n".join(all_items_text))
